---
title: "Writing a Screen Reader in Rust"
publishedAt: "2024-11-20"
summary: "In one weekend"
image: "/images/writing/screen-reader-in-rust/thumbnail.png"
---

### Backstory

In June 2025 a new law, the 'Barrierefreiheitsst√§rkungsgesetz' (BFSG), will come into effect in Germany, requiring _most_ websites to be accessible.
And thus, German website owners are currently scrambling to conform to the new regulations.

This is also how I first got exposed to the topic of web accessibility. More and more of our clients (@[next.motion](https://next-motion.de)) are asking for audits and improvements in this space.

So recently, while working on the accessibility of a website, I got the idea to delve deeper into how screen readers actually work.
What better way to understand something than to build it yourself?

To keep thing simple, I decided to only focus Windows for now because it's by far the most popular OS.

### Choosing the right tools

Screen Readers require low-level access to OS APIs for reading text and interacting with applications.
Rust is pretty much the only low-level programming language I'm somewhat comfortable with.
So it was an easy choice for this project.
The borrow checker&trade; is the cherry on top, because I don't feel like shooting myself in the foot with memory leaks.

As for functionality, I figured a basic screen reader should be able to:

- Access information about UI elements on the screen
- Interact with UI applications
- Read text aloud (text-to-speech)
- Listen and react to user input
- Play audio files (for sound effects)

After searching around GitHub a bit I found [leexgone/uiautomation-rs](https://github.com/leexgone/uiautomation-rs).
It's a Rust wrapper around the Windows UI Automation API, which provides programmatic access to most user interface elements on the desktop as well as the ability to interact with them programmatically.
This is exactly what I need for points 1 and 2 on my list!

Now for text-to-speech, I knew that Windows has a built-in text-to-speech API, I just needed a way to access it. Luckily, there is a Rust crate that provides raw FFI bindings to the *whole* Windows API: [retep998/winapi-rs](https://github.com/retep998/winapi-rs).
This should cover point 3.

For points 4 and 5, I searched for utility crates on [crates.io](https://crates.io) and found [rodio](https://crates.io/crates/rodio) for audio playback and [mki](https://crates.io/crates/mki) for keyboard input.

### The Implementation

I set up a new Rust project and added the dependencies mentioned above.
Then I started implementing the basic functionality:

1. Sounds

This is quite simple. Only three sounds are needed:
a startup sound, a shutdown sound, and a sound for when the user focuses an input field.
Because there are so little, I skipped any fancy asset management and just included the sound files as byte arrays in the source code.

```rust
use rodio::{Decoder, OutputStream, Sink};
use std::io::Cursor;

pub const STARTUP_SOUND: &[u8] = include_bytes!("../assets/sounds/startup.mp3");
pub const SHUTDOWN_SOUND: &[u8] = include_bytes!("../assets/sounds/shutdown.mp3");
pub const INPUT_FOCUSSED_SOUND: &[u8] = include_bytes!("../assets/sounds/input-focussed.mp3");

/// Plays the given sound data asynchronously on the default audio output.
pub fn play_sound(sound_data: &[u8]) {
    let sound_data_clone = sound_data.to_vec();

    std::thread::spawn(move || {
        let (_stream, stream_handle) = OutputStream::try_default().unwrap();
        let sink = Sink::try_new(&stream_handle).unwrap();

        let cursor = Cursor::new(sound_data_clone);
        let source = Decoder::new(cursor).unwrap();

        sink.append(source);

        sink.sleep_until_end();
    });
}
```
